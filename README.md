# üì∑ Perspective-n-Point (PnP) Tutorial

A detailed discussion on PnP.

## Introduction

Imagine you took an image of your house and showed it to your friend, and asked a simple question:

> ‚ÄúCan you tell me where this photograph is taken from?‚Äù

Will your friend be able to guess the spot?
If yes, then how?
How does our brain figure out the **location of the camera** just by looking at the image?

Well, this is a well-known problem in **Photogrammetry**, known as the **Perspective-n-Point (PnP)** problem.

---

## What Is PnP?

PnP is the problem of **estimating the relative pose of the camera** with respect to the environment,
given the **point correspondences** between the environment and the image.

---

### Let‚Äôs break it down

* **Pose** ‚Üí Position and orientation of the camera in the environment.
* **Relative** ‚Üí Because we need a reference coordinate system to define the camera‚Äôs pose.

  > Example: ‚ÄúThe camera is 2 meters in front of the main door and inclined 45¬∞ upward from the ground.‚Äù
* **Point correspondences** ‚Üí Which part of the 3D world corresponds to which part of the 2D image.

---

<div>![Point Correspondences between 3D Environment and Camera Image](media/pnp_correspondences.png)</div>

The figure above shows how an image of a 3D environment is captured by a camera.
Here, the 3D points **X‚ÇÅ, X‚ÇÇ, X‚ÇÉ** correspond to 2D image points **x‚ÇÅ, x‚ÇÇ, x‚ÇÉ**.

Finding these correspondences seems intuitive for humans, but it‚Äôs a **big challenge for computers**.

> üëâ *Click here to try an interactive version of this figure*

---

Basically, if we are given enough point correspondences, we can mathematically find the camera pose.
But how much is enough?

Math says: only **three perfect point correspondences** are enough to recover the camera pose.
Hence, **PnP ‚Üí P3P** problem.

---

## Why Exactly 3 Points?

This has something to do with **Degrees of Freedom**,
which is well explained in the linked video in the original article.

---

## üßÆ Problem Formulation

Let‚Äôs discuss the case of **P3P** and properly define the problem.

**Given:**

* 3D points { X‚ÇÅ, X‚ÇÇ, X‚ÇÉ }
* Their corresponding 2D image points { x‚ÇÅ, x‚ÇÇ, x‚ÇÉ }
* Focal length of the camera *f*

**Find:**

* 3D translation vector of the camera (**t**)
* 3√ó3 rotation matrix of the camera (**R**)

> **Note:**
> We assume an *ideal pinhole camera* (no lens distortion)
> and the **principal point** is exactly at the image center.

If you‚Äôre unfamiliar with these concepts, see the author‚Äôs upcoming post on *Single View Geometry*.

---

## üî¢ Solution Steps

To simplify the process, let‚Äôs break it into **four main steps**:

1. Compute angles between projection rays
2. Compute lengths of projection rays
3. Identify the correct solution
4. Compute the pose

---

### 1Ô∏è‚É£ Compute Angles Between Projection Rays

**Given:** Image points { x‚ÇÅ, x‚ÇÇ, x‚ÇÉ } and focal length *f*
**Find:** Angles between projection rays { Œ±, Œ≤, Œ≥ }

<div>![Image Formation in Pinhole Camera Model](media/pinhole_model.png)</div>

Assume everything is defined in the **camera coordinate system**,
with the camera at **(0, 0, 0)** facing the +Z axis.

<div>![Coordinates in the Image Plane](media/image_plane_coords.png)</div>

---

### 2Ô∏è‚É£ Compute Lengths of Projection Rays

**Given:** Angles { Œ±, Œ≤, Œ≥ } and 3D points { X‚ÇÅ, X‚ÇÇ, X‚ÇÉ }
**Find:** Lengths { s‚ÇÅ, s‚ÇÇ, s‚ÇÉ }

<div>![Tetrahedron Geometry](media/tetrahedron_geometry.png)</div>

This step deals with the **geometry of tetrahedron X‚ÇÄ‚ÄìX‚ÇÅ‚ÄìX‚ÇÇ‚ÄìX‚ÇÉ**.

First, find relative distances between the 3D points { a, b, c },
using simple Euclidean distance.

<div>![Relative Distances Between 3D Points](media/distances_between_points.png)</div>

To find { s‚ÇÅ, s‚ÇÇ, s‚ÇÉ }, apply the **Law of Cosines**.

For triangle X‚ÇÄ‚ÄìX‚ÇÅ‚ÄìX‚ÇÇ:

<div>![Law of Cosines Equation Illustration](media/law_of_cosines.png)</div>

Repeat the same for all three faces of the tetrahedron.

<div>![Equations of All Faces](media/tetrahedron_equations.png)</div>

Equation (vii) yields a **fourth-degree polynomial**.
Solving it gives **four possible values** for *v*,
which can be substituted into equation (vi) to obtain *u*.

Hence, we get **four sets of (u,v)** values ‚Äî only one of which is correct.

---

### 3Ô∏è‚É£ Identify the Correct Solution

<div>![Four Possible Solutions](media/four_possible_solutions.png)</div>

Geometrically, it‚Äôs possible to get **four different sets** of { s‚ÇÅ, s‚ÇÇ, s‚ÇÉ }
for the same angles { Œ±, Œ≤, Œ≥ } and relative distances { a, b, c }.

**Methods to choose the correct solution:**

1. Use additional sensors like **GPS** or **IMU** to get an initial pose estimate
   and select the solution nearest to it.
2. Use **more correspondence points** ‚Äî e.g., add a fourth pair (X‚ÇÑ, x‚ÇÑ).

   * Compute four camera poses using Step 4 below and check which aligns best with X‚ÇÑ.
   * Alternatively, solve for { s‚ÇÅ, s‚ÇÇ, s‚ÇÑ }, { s‚ÇÇ, s‚ÇÉ, s‚ÇÑ }, { s‚ÇÅ, s‚ÇÉ, s‚ÇÑ }
     and find the set consistent with previous { s‚ÇÅ, s‚ÇÇ, s‚ÇÉ } values.

---

### 4Ô∏è‚É£ Compute Pose

**Given:** Complete tetrahedron geometry
**Find:** Camera pose ‚Äî rotation matrix R<sub>c</sub> and translation vector t<sub>c</sub>

<div>![Camera Pose Computation Diagram](media/pose_computation.png)</div>

We already have { X‚ÇÅ, X‚ÇÇ, X‚ÇÉ } in both **camera** and **world** coordinate systems.
Now we need a **transformation from camera ‚Üí world coordinates**,
which lets us transform the camera position to obtain the final **camera pose**.

This is a classic **3D registration** (or point-cloud alignment) problem,
also known as *scan matching*.

> The author will cover this topic in a future post.
> You can check related works referenced in the article for more ideas.

---

## üí≠ Final Thoughts

This post explains one of the earliest variants of the **PnP algorithms**,
originally proposed by **Grunert in 1841**.

Centuries later, we have much faster and more robust solutions
(e.g., OpenCV‚Äôs `solvePnP`, PyPose implementations).
Still, understanding the **original geometric formulation**
helps you apply and debug modern methods more effectively.

---

## üìö References

* *Multiple View Geometry in Computer Vision* ‚Äî Richard Hartley & Andrew Zisserman
* Presentation and slides by **Prof. Cyrill Stachniss**
* Blog post by **Jingnan Shi**
* Lecture by **Prof. Steven LaValle**

